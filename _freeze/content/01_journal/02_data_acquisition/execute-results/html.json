{
  "hash": "6d5a3edff45dee44160ae8729ff59cc6",
  "result": {
    "markdown": "---\ntitle: \"Data Acquisition\"\nauthor: \"Subramanya Nanjangud Gurumurthy\"\n---\n\n\n::: callout-note\nYou can delete everything in here and start fresh.\n:::\n\n# Data Acquisition:\n\nData acquisition in R refers to the process of obtaining data from various sources and loading it into R for analysis and manipulation. \nR provides several functions and packages that facilitate data acquisition from different types of sources, such as files, databases, web APIs, and more. \nHere is an introduction to some common methods of data acquisition in R:\n\nReading from Files:\n\n* read.csv(): Reads data from a CSV (Comma-Separated Values) file.\n* read.table(): Reads data from a delimited text file.\n* read_excel(): Reads data from an Excel file.\n* readr package: Provides efficient functions for reading various file formats.\n\nConnecting to Databases:\n\n* DBI package: Provides a consistent interface for connecting to and querying databases.\n* dbConnect(): Establishes a connection to a database.\n* dbGetQuery(): Executes a SQL query and retrieves data from a database.\n\nWeb Scraping:\n\n* rvest package: Allows scraping data from websites using CSS selectors or XPath expressions.\n* httr package: Provides functions for making HTTP requests and retrieving web content.\n\nWeb APIs:\n\n* httr package: Supports interacting with web APIs using HTTP requests (GET, POST, etc.).\n* jsonlite package: Enables parsing and manipulating data in JSON format.\n\nOther Sources:\n\n* readr and haven packages: Support reading data from SAS, SPSS, and Stata files.\n* RODBC package: Connects to ODBC-compliant databases.\n\nThese are just a few examples of data acquisition methods in R. Depending on your specific needs, there may be other packages and functions available to acquire data from specific sources or formats. \nThe choice of method depends on the type of data, its source, and the desired data format for further analysis in R.\n\n# Challenge 1:\n\nGet some data via an API. There are millions of providers, that offer API access for free and have good documentation about how to query their service. You just have to google them. You can use whatever service you want. \nFor example, you can get data about your listening history (spotify), get data about flights (skyscanner) or just check the weather forecast. Print the data in a readable format, e.g. a table if you want, you could also plot it.\n\nIn this task I have used weather website [Open-Meteo](https://api.open-meteo.com/v1/) for solving the task. I have considered Temperature, Relative Humidity, Rain, Precipitation Probability as parameters for the location Hamburg.\n\n## Solution Explaination:\n\n* The code loads the necessary packages: httr for making HTTP requests and jsonlite for parsing JSON data.\n\n* The desired location, \"Hamburg,\" is set.\n\n* The API request URL is constructed with the latitude, longitude, and the specific weather parameters to retrieve (temperature, relative humidity, precipitation probability, and rain).\n\n* The GET() function from httr sends the API request and retrieves the response.\n\n* The code checks if the request was successful by verifying the status code (200).\n\n* If the request was successful, the JSON response is parsed using fromJSON() from jsonlite. The flatten = TRUE argument ensures a flat structure for easier data extraction.\n\n* The relevant weather data (temperature, time, relative humidity, rain, and precipitation probability) is extracted from the parsed JSON.\n\n* The code then prints the location and the units of measurement for each weather parameter.\n\n* The extracted data is stored in a data frame (df).\n\n* Finally, the data frame is printed to display the weather data.\n\nThe complete code: \n\n\n::: {.cell hash='02_data_acquisition_cache/html/unnamed-chunk-1_b75e39cac53782171cafdec72ddfe6fe'}\n\n```{.r .cell-code}\n##############################################################################################\n#1st task\n##############################################################################################\n\nlibrary(httr)\nlibrary(jsonlite)\n\n# Set the desired location\nlocation <- \"Hamburg\"\n\n#the API request URL\nurl <- \"https://api.open-meteo.com/v1/forecast?latitude=48.75&longitude=9.10&hourly=temperature_2m,relativehumidity_2m,precipitation_probability,rain\"\n\n# Send the API request and retrieve the response\nresponse <- GET(url)\n\n\n# Check if the request was successful (status code 200)\nif (status_code(response) == 200) {\n  # Parse the JSON response\n  data <- fromJSON(content(response, \"text\"), flatten = TRUE)\n  \n  # Extract the relevant data\n  temperature <- data$hourly$temperature_2m\n  time <- data$hourly$time\n  relativehumidity <- data$hourly$relativehumidity_2m\n  rain <- data$hourly$rain\n  precip_probability <- data$hourly$precipitation_probability\n  \n  # Print the weather data\n  cat(\"Weather in\", location, \"\\n\")\n  cat(\"Units:\\n\")\n  cat(\"Temperature:\",\"°C\\n\")\n  cat(\"Relative Humidity:\",\"%\\n\")\n  cat(\"Precipitation:\", \"mm\\n\")\n  cat(\"Rain:\",\"mm\\n\")\n  \n  df <- data.frame(\"Date_T_Time\" = time, \"Temperature\" = temperature, \"Relative_Humidity\" = relativehumidity,\n                   \"Rain\" = rain, \"Precipitation_Probability\" = precip_probability)\n  \n  print(head(df, 25))\t\n  plot(df)\n  \n} else {\n  cat(\"Error:\", status_code(response), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Weather in Hamburg \n#> Units:\n#> Temperature: °C\n#> Relative Humidity: %\n#> Precipitation: mm\n#> Rain: mm\n#>         Date_T_Time Temperature Relative_Humidity Rain\n#> 1  2023-05-20T00:00        10.3                79    0\n#> 2  2023-05-20T01:00        10.5                82    0\n#> 3  2023-05-20T02:00         9.8                87    0\n#> 4  2023-05-20T03:00         9.7                87    0\n#> 5  2023-05-20T04:00         9.6                89    0\n#> 6  2023-05-20T05:00        10.3                87    0\n#> 7  2023-05-20T06:00        11.2                85    0\n#> 8  2023-05-20T07:00        12.8                80    0\n#> 9  2023-05-20T08:00        14.3                72    0\n#> 10 2023-05-20T09:00        15.4                68    0\n#> 11 2023-05-20T10:00        16.6                64    0\n#> 12 2023-05-20T11:00        18.5                56    0\n#> 13 2023-05-20T12:00        19.7                50    0\n#> 14 2023-05-20T13:00        20.6                47    0\n#> 15 2023-05-20T14:00        20.0                50    0\n#> 16 2023-05-20T15:00        21.4                46    0\n#> 17 2023-05-20T16:00        21.1                49    0\n#> 18 2023-05-20T17:00        20.6                56    0\n#> 19 2023-05-20T18:00        19.8                65    0\n#> 20 2023-05-20T19:00        17.3                71    0\n#> 21 2023-05-20T20:00        16.2                74    0\n#> 22 2023-05-20T21:00        15.9                75    0\n#> 23 2023-05-20T22:00        15.7                74    0\n#> 24 2023-05-20T23:00        15.0                77    0\n#> 25 2023-05-21T00:00        14.6                79    0\n#>    Precipitation_Probability\n#> 1                          0\n#> 2                          0\n#> 3                          0\n#> 4                          0\n#> 5                          0\n#> 6                          0\n#> 7                          0\n#> 8                          0\n#> 9                          0\n#> 10                         0\n#> 11                         2\n#> 12                         4\n#> 13                         6\n#> 14                         4\n#> 15                         2\n#> 16                         0\n#> 17                         6\n#> 18                        13\n#> 19                        19\n#> 20                        13\n#> 21                         6\n#> 22                         0\n#> 23                         0\n#> 24                         0\n#> 25                         0\n```\n:::\n\n::: {.cell-output-display}\n![](02_data_acquisition_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## Result plot for the challenge:\n\nEven though the program can print a lot of data, for sample I am plotting 15 values from the table for reference in case if online running do not work.\n\n| Date and Time         | Temperature   | Relative Humidity | Rain | Precipitation Probability  |\n|:---------------------:|:-------------:|:-----------------:|:----:|:--------------------------:|\n|   2023-05-20T00:00    |    10.3       |         79        |  0   |             0\t\t|\n|   2023-05-20T01:00    |    10.5       |         82        |  0   |             0\t\t|\n|   2023-05-20T02:00    |     9.8       |         87        |  0   |             0\t\t|\n|   2023-05-20T03:00    |     9.7       |         87        |  0   |             0\t\t|\n|   2023-05-20T04:00    |     9.6       |         89        |  0   |             0\t\t|\n|   2023-05-20T05:00    |    10.3       |         87        |  0   |             0\t\t|\n|   2023-05-20T06:00    |    11.2       |         85        |  0   |             0\t\t|\n|   2023-05-20T07:00    |    12.8       |         80        |  0   |             0\t\t|\n|   2023-05-20T08:00    |    14.3       |         72        |  0   |             0\t\t|\t\t\n|   2023-05-20T09:00    |    15.4       |         68        |  0   |             0\t\t|\n|   2023-05-20T10:00    |    16.6       |         64        |  0   |             2\t\t|\n|   2023-05-20T11:00    |    18.5       |         56        |  0   |             4\t\t|\n|   2023-05-20T12:00    |    19.7       |         50        |  0   |             6\t\t|\n|   2023-05-20T13:00    |    20.6       |         47        |  0   |             4\t\t|\n|   2023-05-20T14:00    |    20.0       |         50        |  0   |             2\t\t|\n\n\n# Challenge 2:\n\nScrape one of the competitor websites of canyon (either https://www.rosebikes.de/ or https://www.radon-bikes.de) and create a small database. The database should contain the model names and prices for at least one category. \nUse the selectorgadget to get a good understanding of the website structure, it is really helpful. After scraping your data, convert it to a readable format. Prices should be in a numeric format without any other letters or symbols. \nAlso check if the prices are reasonable.\n\n## Steps involved in Solution:\n\n* Load the necessary libraries: rvest and dplyr.\n* Define the URL of the competitor website.\n* Read the HTML content of the website using read_html().\n* Scrape the model names by selecting the appropriate HTML elements using CSS selectors (html_nodes()), extracting the text (html_text()), and trimming white spaces (trimws()).\n* Scrape the prices by following a similar process as step 4, but also perform additional data cleaning steps such as removing non-numeric characters, replacing commas with dots, and converting the values to numeric.\n* Define a reasonable price range (maximum price).\n* Filter out rows with prices exceeding the reasonable price range.\n* Create a new variable indicating whether the price is reasonable or not.\n* Iterate over the prices and reasonability using a loop, printing the price and its reasonability.\n* Create a data frame (data) with the scraped model names, prices, and reasonability.\n* Generate a bar plot of the prices by model and reasonability, where reasonable prices are shown in green and unreasonable prices are shown in red.\n* Print the first 10 rows of the data frame.\n\n\nThe complete code: \n\n\n::: {.cell hash='02_data_acquisition_cache/html/unnamed-chunk-2_da86a69ad64d178687f5e35b6e5d6020'}\n\n```{.r .cell-code}\n##############################################################################################\n#2nd task\n##############################################################################################\nlibrary(rvest)\nlibrary(dplyr)\n\n# Define the URL of the competitor website\nurl <- \"https://www.radon-bikes.de/en/mountainbike/hardtail/bikegrid/\"\n\n# Read the HTML content of the website\nhtml <- read_html(url)\n\n# Scrape the model names and prices\nmodel_names <- html %>%\n  html_nodes(\".m-bikegrid__info .a-heading--small\") %>%\n  html_text()%>%\n  trimws()\n\nprices <- html %>%\n  html_nodes(\".m-bikegrid__price--active\") %>%\n  html_text() %>%\n  trimws() %>%\n  gsub(\"[^0-9.,]\", \"\", .) %>%\n  gsub(\",\", \".\", .) %>%\n  as.numeric()\n  \nprices <- na.omit(prices)\n\n# Define the reasonable price range\nmax_price <- 2000  # Maximum reasonable price\n\n# Filter out rows with unreasonable prices\nreasonable_prices <- prices <= max_price\n\nreasonable_list <- ifelse(reasonable_prices, \"Reasonable\", \"Not Reasonable\")\n\n# uncomment this block if you want to print the reasonability individually\n#for (i in seq_along(prices)) {\n#  price <- prices[i]\n#  reasonable <- ifelse(reasonable_prices[i], \"Reasonable\", \"Not Reasonable\")\n#  print(paste(\"Price:\", price, \"| Reasonable:\", reasonable))\n#}\n\n# # Create a data frame with the scraped data\ndata <- data.frame(Model = model_names, Price = prices, Reasonability = reasonable_list)\n\nbarplot(as.numeric(data$Price), names.arg = data$Model, col = ifelse(data$Reasonability == \"Reasonable\", \"green\", \"red\"),\n        xlab = \"Model\", ylab = \"Price\", main = \"Price by Model and Reasonability\")\n```\n\n::: {.cell-output-display}\n![](02_data_acquisition_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Print the first 10 rows of the data frame\nprint(head(data, n = 10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                Model   Price  Reasonability\n#> 1        JEALOUS 8.0 2520.17 Not Reasonable\n#> 2        JEALOUS 9.0 2856.30 Not Reasonable\n#> 3       JEALOUS 10.0 4200.84 Not Reasonable\n#> 4    JEALOUS 10.0 EA 5461.34 Not Reasonable\n#> 5    JEALOUS 10.0 EA 3780.67 Not Reasonable\n#> 6     JEALOUS AL 8.0 1007.56     Reasonable\n#> 7  JEALOUS AL 8.0 HD 1427.73     Reasonable\n#> 8     JEALOUS AL 9.0 1511.76     Reasonable\n#> 9     JEALOUS AL 9.0 1511.76     Reasonable\n#> 10   JEALOUS AL 10.0 1679.83     Reasonable\n```\n:::\n:::\n\n\n## Result Plot: \n\nThe result that was obtained from the local machine. The color of the reasonability has been changed from green, red to blue and yellow for the diffrerentiation:\n\n![Price by Model and Reasonability](../../plots/Task_2/Price_by_model_and_Reasonability.png)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}