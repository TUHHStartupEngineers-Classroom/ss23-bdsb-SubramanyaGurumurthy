[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Tidyverse is a collection of R packages designed to make data manipulation, visualization, and analysis easier and more consistent. It provides a set of tools and functions that follow a consistent grammar and syntax, making it easier to work with data in a tidy and organized manner."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#explanation-on-how-to-solve",
    "href": "content/01_journal/01_tidyverse.html#explanation-on-how-to-solve",
    "title": "Tidyverse",
    "section": "1.1 Explanation On how to solve:",
    "text": "1.1 Explanation On how to solve:\n\nLoad necessary libraries: This code block loads the required libraries, dplyr and ggplot2, which are used for data manipulation and plotting, respectively.\nRead in the data file: The code reads an Excel file named “bike_orderlines_new.xlsx” and assigns it to the variable bike_orderlines_wrangled_tbl_new. The data is stored as a tibble, a modern version of a data frame. Please take care of path to read the file.\nSplit the location data: The separate() function is used to split the “location” column of the bike_orderlines_wrangled_tbl_new tibble into two separate columns, “city” and “state”. The separator used is “,” (comma followed by a space). The original “location” column is retained in the tibble.\nGroup the data and calculate total revenue: The group_by() function groups the data in bike_orderlines_wrangled_tbl_new by “state”. Then, the summarize() function calculates the total revenue by summing the “total_price” column. The results are stored in the sales_by_loc_tbl_new tibble.\nCreate a bar plot: The ggplot() function is used to initialize a new ggplot object, with sales_by_loc_tbl_new as the data. The aesthetic mappings are set with aes(x = state, y = total_revenue). The geom_bar() function is used to create a bar plot with “state” on the x-axis and “total_revenue” on the y-axis. Additional formatting and labeling options are set using labs() and theme() functions.\nGroup the data by state and year and calculate total revenue: Similar to step 4, this code block groups the data by both “state” and “model_year” columns and calculates the total revenue for each group. The results are stored in the sales_by_loc_year_tbl_new tibble.\nCreate a bar plot with facets: This code block creates a bar plot of the total revenue by “model_year” for each “state”. The facet_wrap() function is used to create a grid of plots, with each plot representing a different state. The scales = “free_x” argument allows each facet to have an independent x-axis scale. The ncol = 4 argument sets the number of columns in the grid to 4.\n\nThe Complete solution to challenge:\n##############################################################################################\n#Assignment task\n##############################################################################################\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Read in the data file\nbike_orderlines_wrangled_tbl_new <- read_excel(\"ds_data/01_bike_sales/02_wrangled_data/bike_orderlines_new.xlsx\")\n\n# Split the location data into separate columns for state and city\nbike_orderlines_wrangled_tbl_new <- bike_orderlines_wrangled_tbl_new %>%\nseparate(location, into = c(\"city\", \"state\"), sep = \", \", remove = FALSE)\n\n# Group the data by state and calculate the total revenue\nsales_by_loc_tbl_new <- bike_orderlines_wrangled_tbl_new %>%\ngroup_by(state) %>%\nsummarize(total_revenue = sum(total_price))\n\n# Create a bar plot of the total revenue by state#\nggplot(sales_by_loc_tbl_new, aes(x = state, y = total_revenue)) +\ngeom_bar(stat = \"identity\", fill = \"steelblue\") +\nlabs(title = \"Total Revenue by State\", x = \"State\", y = \"Total Revenue\") +\ntheme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n# Group the data by state and year and calculate the total revenue\nsales_by_loc_year_tbl_new <- bike_orderlines_wrangled_tbl_new %>%\ngroup_by(state, model_year) %>%\nsummarize(total_revenue = sum(total_price))\n\n# Create a bar plot of the total revenue by state and year\nggplot(sales_by_loc_year_tbl_new, aes(x = model_year, y = total_revenue)) +\ngeom_bar(stat = \"identity\", fill = \"steelblue\") +\nlabs(title = \"Total Revenue by State and Year\", x = \"Year\", y = \"Total Revenue\") +\ntheme(axis.text.x = element_text(angle = 45, hjust = 1)) +\nfacet_wrap(~state, scales = \"free_x\", ncol = 4)"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#solution-explaination",
    "href": "content/01_journal/02_data_acquisition.html#solution-explaination",
    "title": "Data Acquisition",
    "section": "\n2.1 Solution Explaination:",
    "text": "2.1 Solution Explaination:\n\nThe code loads the necessary packages: httr for making HTTP requests and jsonlite for parsing JSON data.\nThe desired location, “Hamburg,” is set.\nThe API request URL is constructed with the latitude, longitude, and the specific weather parameters to retrieve (temperature, relative humidity, precipitation probability, and rain).\nThe GET() function from httr sends the API request and retrieves the response.\nThe code checks if the request was successful by verifying the status code (200).\nIf the request was successful, the JSON response is parsed using fromJSON() from jsonlite. The flatten = TRUE argument ensures a flat structure for easier data extraction.\nThe relevant weather data (temperature, time, relative humidity, rain, and precipitation probability) is extracted from the parsed JSON.\nThe code then prints the location and the units of measurement for each weather parameter.\nThe extracted data is stored in a data frame (df).\nFinally, the data frame is printed to display the weather data.\n\nThe complete code:\n\n##############################################################################################\n#1st task\n##############################################################################################\n\nlibrary(httr)\nlibrary(jsonlite)\n\n# Set the desired location\nlocation <- \"Hamburg\"\n\n#the API request URL\nurl <- \"https://api.open-meteo.com/v1/forecast?latitude=48.75&longitude=9.10&hourly=temperature_2m,relativehumidity_2m,precipitation_probability,rain\"\n\n# Send the API request and retrieve the response\nresponse <- GET(url)\n\n\n# Check if the request was successful (status code 200)\nif (status_code(response) == 200) {\n  # Parse the JSON response\n  data <- fromJSON(content(response, \"text\"), flatten = TRUE)\n  \n  # Extract the relevant data\n  temperature <- data$hourly$temperature_2m\n  time <- data$hourly$time\n  relativehumidity <- data$hourly$relativehumidity_2m\n  rain <- data$hourly$rain\n  precip_probability <- data$hourly$precipitation_probability\n  \n  # Print the weather data\n  cat(\"Weather in\", location, \"\\n\")\n  cat(\"Units:\\n\")\n  cat(\"Temperature:\",\"°C\\n\")\n  cat(\"Relative Humidity:\",\"%\\n\")\n  cat(\"Precipitation:\", \"mm\\n\")\n  cat(\"Rain:\",\"mm\\n\")\n  \n  df <- data.frame(\"Date_T_Time\" = time, \"Temperature\" = temperature, \"Relative_Humidity\" = relativehumidity,\n                   \"Rain\" = rain, \"Precipitation_Probability\" = precip_probability)\n  \n  print(head(df, 25))   \n  plot(df)\n  \n} else {\n  cat(\"Error:\", status_code(response), \"\\n\")\n}\n\n#> Weather in Hamburg \n#> Units:\n#> Temperature: °C\n#> Relative Humidity: %\n#> Precipitation: mm\n#> Rain: mm\n#>         Date_T_Time Temperature Relative_Humidity Rain\n#> 1  2023-05-20T00:00        10.3                79    0\n#> 2  2023-05-20T01:00        10.5                82    0\n#> 3  2023-05-20T02:00         9.8                87    0\n#> 4  2023-05-20T03:00         9.7                87    0\n#> 5  2023-05-20T04:00         9.6                89    0\n#> 6  2023-05-20T05:00        10.3                87    0\n#> 7  2023-05-20T06:00        11.2                85    0\n#> 8  2023-05-20T07:00        12.8                80    0\n#> 9  2023-05-20T08:00        14.3                72    0\n#> 10 2023-05-20T09:00        15.4                68    0\n#> 11 2023-05-20T10:00        16.6                64    0\n#> 12 2023-05-20T11:00        18.5                56    0\n#> 13 2023-05-20T12:00        19.7                50    0\n#> 14 2023-05-20T13:00        20.6                47    0\n#> 15 2023-05-20T14:00        20.0                50    0\n#> 16 2023-05-20T15:00        21.4                46    0\n#> 17 2023-05-20T16:00        21.1                49    0\n#> 18 2023-05-20T17:00        20.6                56    0\n#> 19 2023-05-20T18:00        19.8                65    0\n#> 20 2023-05-20T19:00        17.3                71    0\n#> 21 2023-05-20T20:00        16.2                74    0\n#> 22 2023-05-20T21:00        15.9                75    0\n#> 23 2023-05-20T22:00        15.7                74    0\n#> 24 2023-05-20T23:00        15.0                77    0\n#> 25 2023-05-21T00:00        14.6                79    0\n#>    Precipitation_Probability\n#> 1                          0\n#> 2                          0\n#> 3                          0\n#> 4                          0\n#> 5                          0\n#> 6                          0\n#> 7                          0\n#> 8                          0\n#> 9                          0\n#> 10                         0\n#> 11                         2\n#> 12                         4\n#> 13                         6\n#> 14                         4\n#> 15                         2\n#> 16                         0\n#> 17                         6\n#> 18                        13\n#> 19                        19\n#> 20                        13\n#> 21                         6\n#> 22                         0\n#> 23                         0\n#> 24                         0\n#> 25                         0"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#result-plot-for-the-challenge",
    "href": "content/01_journal/02_data_acquisition.html#result-plot-for-the-challenge",
    "title": "Data Acquisition",
    "section": "\n2.2 Result plot for the challenge:",
    "text": "2.2 Result plot for the challenge:\nEven though the program can print a lot of data, for sample I am plotting 15 values from the table for reference.\n\n\n\n\n\n\n\n\n\nDate and Time\nTemperature\nRelative Humidity\nRain\nPrecipitation Probability\n\n\n\n2023-05-20T00:00\n10.3\n79\n0\n0\n\n\n2023-05-20T01:00\n10.5\n82\n0\n0\n\n\n2023-05-20T02:00\n9.8\n87\n0\n0\n\n\n2023-05-20T03:00\n9.7\n87\n0\n0\n\n\n2023-05-20T04:00\n9.6\n89\n0\n0\n\n\n2023-05-20T05:00\n10.3\n87\n0\n0\n\n\n2023-05-20T06:00\n11.2\n85\n0\n0\n\n\n2023-05-20T07:00\n12.8\n80\n0\n0\n\n\n2023-05-20T08:00\n14.3\n72\n0\n0\n\n\n2023-05-20T09:00\n15.4\n68\n0\n0\n\n\n2023-05-20T10:00\n16.6\n64\n0\n2\n\n\n2023-05-20T11:00\n18.5\n56\n0\n4\n\n\n2023-05-20T12:00\n19.7\n50\n0\n6\n\n\n2023-05-20T13:00\n20.6\n47\n0\n4\n\n\n2023-05-20T14:00\n20.0\n50\n0\n2"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "Hi this is Subramanya Nanjangud Gurumurthy. I am part of the course Business Data Science Basics. My Matriculation Number is 54843"
  }
]